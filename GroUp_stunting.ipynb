{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DenisKai7/GroUp/blob/ml-training/GroUp_stunting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Dataset dari github"
      ],
      "metadata": {
        "id": "4RNfYcxX9Co0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/DenisKai7/GroUp.git"
      ],
      "metadata": {
        "id": "rIvIgkdlwQx5",
        "outputId": "8b07c660-bd9b-4a15-80c8-bf52fc37d5a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GroUp'...\n",
            "remote: Enumerating objects: 66, done.\u001b[K\n",
            "remote: Counting objects: 100% (66/66), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 66 (delta 14), reused 4 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (66/66), 90.62 KiB | 1.65 MiB/s, done.\n",
            "Resolving deltas: 100% (14/14), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd GroUp\n",
        "!git checkout dataset"
      ],
      "metadata": {
        "id": "lEf65dKrx245",
        "outputId": "74319701-7add-4a70-d290-01f2c1eafb34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GroUp\n",
            "Branch 'dataset' set up to track remote branch 'dataset' from 'origin'.\n",
            "Switched to a new branch 'dataset'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "bIFso5Jg8S0I",
        "outputId": "3e524c08-1160-4da4-f175-73293d0d931c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.6 alembic-1.14.0 colorlog-6.9.0 optuna-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Library yang dibutuhkan"
      ],
      "metadata": {
        "id": "FT3hSyuGewKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import optuna\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout"
      ],
      "metadata": {
        "id": "pG4nQXIRevwE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**"
      ],
      "metadata": {
        "id": "4aqduzviON3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "load dataset"
      ],
      "metadata": {
        "id": "YGLhyGZLOT9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Dataset\n",
        "data_path = '/content/GroUp/Stunting_Dataset.csv'\n",
        "nutrition_data_path = '/content/GroUp/nutrition.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "nutrition_data = pd.read_csv(nutrition_data_path)\n",
        "\n",
        "#Preprocessing Data\n",
        "class DataPreprocessor:\n",
        "    def init(self, data):\n",
        "        self.data = data\n",
        "        self.scaler = StandardScaler()\n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "    def preprocess(self):\n",
        "        # Handle missing values\n",
        "        self._handle_missing_values()\n",
        "        # Feature engineering\n",
        "        self._feature_engineering()\n",
        "        return self._prepare_model_data()\n",
        "\n",
        "    def _handle_missing_values(self):\n",
        "        numeric_columns = self.data.select_dtypes(include=[np.number]).columns\n",
        "        self.data[numeric_columns] = self.data[numeric_columns].fillna(\n",
        "            self.data[numeric_columns].median()\n",
        "        )\n",
        "\n",
        "    def _feature_engineering(self):\n",
        "        self.data['BMI'] = self.data['Body Weight'] / ((self.data['Body Length'] / 100) ** 2)\n",
        "        self.data['Gender_Encoded'] = self.label_encoder.fit_transform(self.data['Gender'])\n",
        "\n",
        "    def _prepare_model_data(self):\n",
        "        features = ['Age', 'Birth Weight', 'Birth Length', 'Body Weight',\n",
        "                    'Body Length', 'BMI', 'Gender_Encoded']\n",
        "        X = self.data[features]\n",
        "        y = self.label_encoder.fit_transform(self.data['Stunting'])\n",
        "\n",
        "        X_scaled = self.scaler.fit_transform(X)\n",
        "        return X_scaled, y\n",
        "\n",
        "preprocessor = DataPreprocessor(data)\n",
        "X, y = preprocessor.preprocess()"
      ],
      "metadata": {
        "id": "2qgDi8uU1RG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Tkw_VnZ4CUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "23pnwdMJPLJH"
      }
    }
  ]
}