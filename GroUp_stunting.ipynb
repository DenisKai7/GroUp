{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DenisKai7/GroUp/blob/ml-training/GroUp_stunting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Dataset dari github"
      ],
      "metadata": {
        "id": "4RNfYcxX9Co0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/DenisKai7/GroUp.git"
      ],
      "metadata": {
        "id": "rIvIgkdlwQx5",
        "outputId": "e09804f9-c7fb-4b47-dbce-07127499e0b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GroUp'...\n",
            "remote: Enumerating objects: 69, done.\u001b[K\n",
            "remote: Counting objects: 100% (69/69), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 69 (delta 15), reused 4 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (69/69), 92.22 KiB | 2.36 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd GroUp\n",
        "!git checkout dataset"
      ],
      "metadata": {
        "id": "lEf65dKrx245",
        "outputId": "f8bf2a07-69b9-42b7-ff98-cc558896cc55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GroUp\n",
            "Branch 'dataset' set up to track remote branch 'dataset' from 'origin'.\n",
            "Switched to a new branch 'dataset'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "bIFso5Jg8S0I",
        "outputId": "92cc7325-c6d5-4c44-9cdd-2a918cbcfaac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.6 alembic-1.14.0 colorlog-6.9.0 optuna-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Library yang dibutuhkan"
      ],
      "metadata": {
        "id": "FT3hSyuGewKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import optuna\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout"
      ],
      "metadata": {
        "id": "pG4nQXIRevwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**"
      ],
      "metadata": {
        "id": "4aqduzviON3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "load dataset"
      ],
      "metadata": {
        "id": "YGLhyGZLOT9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Dataset\n",
        "data_path = '/content/GroUp/Stunting_Dataset.csv'\n",
        "nutrition_data_path = '/content/GroUp/nutrition.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "nutrition_data = pd.read_csv(nutrition_data_path)\n",
        "\n",
        "#Preprocessing Data\n",
        "class DataPreprocessor:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.scaler = StandardScaler()\n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "    def preprocess(self):\n",
        "        # Handle missing values\n",
        "        self._handle_missing_values()\n",
        "        # Feature engineering\n",
        "        self._feature_engineering()\n",
        "        return self._prepare_model_data()\n",
        "\n",
        "    def _handle_missing_values(self):\n",
        "        numeric_columns = self.data.select_dtypes(include=[np.number]).columns\n",
        "        self.data[numeric_columns] = self.data[numeric_columns].fillna(\n",
        "            self.data[numeric_columns].median()\n",
        "        )\n",
        "\n",
        "    def _feature_engineering(self):\n",
        "        self.data['BMI'] = self.data['Body Weight'] / ((self.data['Body Length'] / 100) ** 2)\n",
        "        self.data['Gender_Encoded'] = self.label_encoder.fit_transform(self.data['Gender'])\n",
        "\n",
        "    def _prepare_model_data(self):\n",
        "        features = ['Age', 'Birth Weight', 'Birth Length', 'Body Weight',\n",
        "                    'Body Length', 'BMI', 'Gender_Encoded']\n",
        "        X = self.data[features]\n",
        "        y = self.label_encoder.fit_transform(self.data['Stunting'])\n",
        "\n",
        "        X_scaled = self.scaler.fit_transform(X)\n",
        "        return X_scaled, y\n",
        "\n",
        "preprocessor = DataPreprocessor(data)\n",
        "X, y = preprocessor.preprocess()"
      ],
      "metadata": {
        "id": "2qgDi8uU1RG5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelTrainer:\n",
        "    def __init__(self):\n",
        "        self.models = {}\n",
        "\n",
        "    def train_random_forest(self, X, y):\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
        "                'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "                'min_samples_split': trial.suggest_int('min_samples_split', 2, 10)\n",
        "            }\n",
        "\n",
        "            rf = RandomForestClassifier(**params)\n",
        "            rf.fit(X, y)\n",
        "\n",
        "            y_pred = rf.predict(X)\n",
        "            return accuracy_score(y, y_pred)\n",
        "\n",
        "        study = optuna.create_study(direction='maximize')\n",
        "        study.optimize(objective, n_trials=50)\n",
        "\n",
        "        best_rf = RandomForestClassifier(**study.best_params)\n",
        "        best_rf.fit(X, y)\n",
        "        return best_rf, study.best_params\n",
        "\n",
        "trainer = ModelTrainer()\n",
        "rf_model, rf_params = trainer.train_random_forest(X, y)"
      ],
      "metadata": {
        "id": "7Tkw_VnZ4CUV",
        "outputId": "1e59b36e-9ff9-4624-e75e-26793b0b04fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-12 16:10:13,705] A new study created in memory with name: no-name-d6397159-2819-4d8e-bc1d-9e5efe83ebc7\n",
            "[I 2024-11-12 16:10:14,255] Trial 0 finished with value: 0.8604 and parameters: {'n_estimators': 109, 'max_depth': 5, 'min_samples_split': 5}. Best is trial 0 with value: 0.8604.\n",
            "[I 2024-11-12 16:10:14,498] Trial 1 finished with value: 0.8511 and parameters: {'n_estimators': 59, 'max_depth': 3, 'min_samples_split': 9}. Best is trial 0 with value: 0.8604.\n",
            "[I 2024-11-12 16:10:15,307] Trial 2 finished with value: 0.8615 and parameters: {'n_estimators': 164, 'max_depth': 5, 'min_samples_split': 3}. Best is trial 2 with value: 0.8615.\n",
            "[I 2024-11-12 16:10:16,927] Trial 3 finished with value: 0.8774 and parameters: {'n_estimators': 252, 'max_depth': 8, 'min_samples_split': 7}. Best is trial 3 with value: 0.8774.\n",
            "[I 2024-11-12 16:10:18,243] Trial 4 finished with value: 0.8717 and parameters: {'n_estimators': 219, 'max_depth': 7, 'min_samples_split': 3}. Best is trial 3 with value: 0.8774.\n",
            "[I 2024-11-12 16:10:19,076] Trial 5 finished with value: 0.8868 and parameters: {'n_estimators': 99, 'max_depth': 9, 'min_samples_split': 3}. Best is trial 5 with value: 0.8868.\n",
            "[I 2024-11-12 16:10:20,071] Trial 6 finished with value: 0.8556 and parameters: {'n_estimators': 149, 'max_depth': 4, 'min_samples_split': 7}. Best is trial 5 with value: 0.8868.\n",
            "[I 2024-11-12 16:10:21,513] Trial 7 finished with value: 0.8716 and parameters: {'n_estimators': 163, 'max_depth': 7, 'min_samples_split': 4}. Best is trial 5 with value: 0.8868.\n",
            "[I 2024-11-12 16:10:23,003] Trial 8 finished with value: 0.8655 and parameters: {'n_estimators': 234, 'max_depth': 6, 'min_samples_split': 5}. Best is trial 5 with value: 0.8868.\n",
            "[I 2024-11-12 16:10:24,001] Trial 9 finished with value: 0.8556 and parameters: {'n_estimators': 231, 'max_depth': 4, 'min_samples_split': 2}. Best is trial 5 with value: 0.8868.\n",
            "[I 2024-11-12 16:10:24,387] Trial 10 finished with value: 0.8846 and parameters: {'n_estimators': 51, 'max_depth': 10, 'min_samples_split': 10}. Best is trial 5 with value: 0.8868.\n",
            "[I 2024-11-12 16:10:24,792] Trial 11 finished with value: 0.8789 and parameters: {'n_estimators': 54, 'max_depth': 9, 'min_samples_split': 10}. Best is trial 5 with value: 0.8868.\n",
            "[I 2024-11-12 16:10:25,500] Trial 12 finished with value: 0.8859 and parameters: {'n_estimators': 94, 'max_depth': 10, 'min_samples_split': 8}. Best is trial 5 with value: 0.8868.\n",
            "[I 2024-11-12 16:10:26,324] Trial 13 finished with value: 0.8874 and parameters: {'n_estimators': 108, 'max_depth': 10, 'min_samples_split': 8}. Best is trial 13 with value: 0.8874.\n",
            "[I 2024-11-12 16:10:27,190] Trial 14 finished with value: 0.8842 and parameters: {'n_estimators': 121, 'max_depth': 9, 'min_samples_split': 6}. Best is trial 13 with value: 0.8874.\n",
            "[I 2024-11-12 16:10:28,557] Trial 15 finished with value: 0.8821 and parameters: {'n_estimators': 193, 'max_depth': 9, 'min_samples_split': 8}. Best is trial 13 with value: 0.8874.\n",
            "[I 2024-11-12 16:10:29,210] Trial 16 finished with value: 0.8799 and parameters: {'n_estimators': 90, 'max_depth': 8, 'min_samples_split': 2}. Best is trial 13 with value: 0.8874.\n",
            "[I 2024-11-12 16:10:31,428] Trial 17 finished with value: 0.8902 and parameters: {'n_estimators': 294, 'max_depth': 10, 'min_samples_split': 6}. Best is trial 17 with value: 0.8902.\n",
            "[I 2024-11-12 16:10:34,217] Trial 18 finished with value: 0.89 and parameters: {'n_estimators': 286, 'max_depth': 10, 'min_samples_split': 6}. Best is trial 17 with value: 0.8902.\n",
            "[I 2024-11-12 16:10:36,578] Trial 19 finished with value: 0.878 and parameters: {'n_estimators': 300, 'max_depth': 8, 'min_samples_split': 6}. Best is trial 17 with value: 0.8902.\n",
            "[I 2024-11-12 16:10:38,791] Trial 20 finished with value: 0.8911 and parameters: {'n_estimators': 298, 'max_depth': 10, 'min_samples_split': 5}. Best is trial 20 with value: 0.8911.\n",
            "[I 2024-11-12 16:10:40,966] Trial 21 finished with value: 0.8911 and parameters: {'n_estimators': 290, 'max_depth': 10, 'min_samples_split': 5}. Best is trial 20 with value: 0.8911.\n",
            "[I 2024-11-12 16:10:42,953] Trial 22 finished with value: 0.8911 and parameters: {'n_estimators': 266, 'max_depth': 10, 'min_samples_split': 5}. Best is trial 20 with value: 0.8911.\n",
            "[I 2024-11-12 16:10:44,876] Trial 23 finished with value: 0.8852 and parameters: {'n_estimators': 270, 'max_depth': 9, 'min_samples_split': 4}. Best is trial 20 with value: 0.8911.\n",
            "[I 2024-11-12 16:10:47,091] Trial 24 finished with value: 0.8777 and parameters: {'n_estimators': 262, 'max_depth': 8, 'min_samples_split': 5}. Best is trial 20 with value: 0.8911.\n",
            "[I 2024-11-12 16:10:49,955] Trial 25 finished with value: 0.8934 and parameters: {'n_estimators': 279, 'max_depth': 10, 'min_samples_split': 4}. Best is trial 25 with value: 0.8934.\n",
            "[I 2024-11-12 16:10:51,348] Trial 26 finished with value: 0.8851 and parameters: {'n_estimators': 197, 'max_depth': 9, 'min_samples_split': 4}. Best is trial 25 with value: 0.8934.\n",
            "[I 2024-11-12 16:10:53,074] Trial 27 finished with value: 0.8716 and parameters: {'n_estimators': 286, 'max_depth': 7, 'min_samples_split': 4}. Best is trial 25 with value: 0.8934.\n",
            "[I 2024-11-12 16:10:54,977] Trial 28 finished with value: 0.8949 and parameters: {'n_estimators': 248, 'max_depth': 10, 'min_samples_split': 3}. Best is trial 28 with value: 0.8949.\n",
            "[I 2024-11-12 16:10:56,367] Trial 29 finished with value: 0.8656 and parameters: {'n_estimators': 248, 'max_depth': 6, 'min_samples_split': 3}. Best is trial 28 with value: 0.8949.\n",
            "[I 2024-11-12 16:10:57,754] Trial 30 finished with value: 0.8796 and parameters: {'n_estimators': 208, 'max_depth': 8, 'min_samples_split': 2}. Best is trial 28 with value: 0.8949.\n",
            "[I 2024-11-12 16:11:00,057] Trial 31 finished with value: 0.891 and parameters: {'n_estimators': 279, 'max_depth': 10, 'min_samples_split': 5}. Best is trial 28 with value: 0.8949.\n",
            "[I 2024-11-12 16:11:03,346] Trial 32 finished with value: 0.8916 and parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 4}. Best is trial 28 with value: 0.8949.\n",
            "[I 2024-11-12 16:11:05,384] Trial 33 finished with value: 0.8857 and parameters: {'n_estimators': 254, 'max_depth': 9, 'min_samples_split': 4}. Best is trial 28 with value: 0.8949.\n",
            "[I 2024-11-12 16:11:08,185] Trial 34 finished with value: 0.894 and parameters: {'n_estimators': 272, 'max_depth': 10, 'min_samples_split': 3}. Best is trial 28 with value: 0.8949.\n",
            "[I 2024-11-12 16:11:09,902] Trial 35 finished with value: 0.8867 and parameters: {'n_estimators': 239, 'max_depth': 9, 'min_samples_split': 3}. Best is trial 28 with value: 0.8949.\n",
            "[I 2024-11-12 16:11:10,990] Trial 36 finished with value: 0.8536 and parameters: {'n_estimators': 271, 'max_depth': 3, 'min_samples_split': 3}. Best is trial 28 with value: 0.8949.\n",
            "[I 2024-11-12 16:11:12,653] Trial 37 finished with value: 0.8973 and parameters: {'n_estimators': 220, 'max_depth': 10, 'min_samples_split': 2}. Best is trial 37 with value: 0.8973.\n",
            "[I 2024-11-12 16:11:14,450] Trial 38 finished with value: 0.8797 and parameters: {'n_estimators': 215, 'max_depth': 8, 'min_samples_split': 2}. Best is trial 37 with value: 0.8973.\n",
            "[I 2024-11-12 16:11:16,713] Trial 39 finished with value: 0.8858 and parameters: {'n_estimators': 223, 'max_depth': 9, 'min_samples_split': 3}. Best is trial 37 with value: 0.8973.\n",
            "[I 2024-11-12 16:11:18,470] Trial 40 finished with value: 0.887 and parameters: {'n_estimators': 246, 'max_depth': 9, 'min_samples_split': 2}. Best is trial 37 with value: 0.8973.\n",
            "[I 2024-11-12 16:11:20,473] Trial 41 finished with value: 0.8947 and parameters: {'n_estimators': 258, 'max_depth': 10, 'min_samples_split': 3}. Best is trial 37 with value: 0.8973.\n",
            "[I 2024-11-12 16:11:22,392] Trial 42 finished with value: 0.895 and parameters: {'n_estimators': 256, 'max_depth': 10, 'min_samples_split': 3}. Best is trial 37 with value: 0.8973.\n",
            "[I 2024-11-12 16:11:24,100] Trial 43 finished with value: 0.8952 and parameters: {'n_estimators': 227, 'max_depth': 10, 'min_samples_split': 3}. Best is trial 37 with value: 0.8973.\n",
            "[I 2024-11-12 16:11:25,453] Trial 44 finished with value: 0.896 and parameters: {'n_estimators': 179, 'max_depth': 10, 'min_samples_split': 2}. Best is trial 37 with value: 0.8973.\n",
            "[I 2024-11-12 16:11:26,388] Trial 45 finished with value: 0.861 and parameters: {'n_estimators': 177, 'max_depth': 5, 'min_samples_split': 2}. Best is trial 37 with value: 0.8973.\n",
            "[I 2024-11-12 16:11:28,263] Trial 46 finished with value: 0.8874 and parameters: {'n_estimators': 179, 'max_depth': 9, 'min_samples_split': 2}. Best is trial 37 with value: 0.8973.\n",
            "[I 2024-11-12 16:11:30,003] Trial 47 finished with value: 0.8945 and parameters: {'n_estimators': 153, 'max_depth': 10, 'min_samples_split': 3}. Best is trial 37 with value: 0.8973.\n",
            "[I 2024-11-12 16:11:31,693] Trial 48 finished with value: 0.8869 and parameters: {'n_estimators': 227, 'max_depth': 9, 'min_samples_split': 2}. Best is trial 37 with value: 0.8973.\n",
            "[I 2024-11-12 16:11:33,183] Trial 49 finished with value: 0.8952 and parameters: {'n_estimators': 197, 'max_depth': 10, 'min_samples_split': 3}. Best is trial 37 with value: 0.8973.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_lstm_model(input_shape):\n",
        "    model = Sequential([\n",
        "        LSTM(64, input_shape=input_shape, return_sequences=True),\n",
        "        Dropout(0.3),\n",
        "        LSTM(32, return_sequences=False),\n",
        "        Dropout(0.3),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    return model\n",
        "\n",
        "lstm_model = create_lstm_model((X.shape[1], 1))\n",
        "lstm_model.summary()\n",
        "\n",
        "# Transforming data for LSTM\n",
        "X_lstm = np.expand_dims(X, axis=2)\n",
        "y_lstm = y.astype(float)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_lstm, y_lstm, test_size=0.2)\n",
        "lstm_history = lstm_model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "id": "pLVVkURyI3BO",
        "outputId": "79440558-888a-43e5-c884-d3acd59dd8a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │          \u001b[38;5;34m16,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m12,416\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,345\u001b[0m (114.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,345</span> (114.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,345\u001b[0m (114.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,345</span> (114.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.3056 - val_loss: 0.1558\n",
            "Epoch 2/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - loss: 0.1652 - val_loss: 0.1546\n",
            "Epoch 3/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.1527 - val_loss: 0.1393\n",
            "Epoch 4/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - loss: 0.1424 - val_loss: 0.1358\n",
            "Epoch 5/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.1311 - val_loss: 0.1343\n",
            "Epoch 6/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1258 - val_loss: 0.1328\n",
            "Epoch 7/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1247 - val_loss: 0.1274\n",
            "Epoch 8/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1216 - val_loss: 0.1251\n",
            "Epoch 9/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1188 - val_loss: 0.1251\n",
            "Epoch 10/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1159 - val_loss: 0.1240\n",
            "Epoch 11/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1197 - val_loss: 0.1245\n",
            "Epoch 12/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1151 - val_loss: 0.1258\n",
            "Epoch 13/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1173 - val_loss: 0.1233\n",
            "Epoch 14/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.1175 - val_loss: 0.1230\n",
            "Epoch 15/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.1127 - val_loss: 0.1244\n",
            "Epoch 16/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1160 - val_loss: 0.1236\n",
            "Epoch 17/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1126 - val_loss: 0.1239\n",
            "Epoch 18/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1135 - val_loss: 0.1230\n",
            "Epoch 19/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1145 - val_loss: 0.1216\n",
            "Epoch 20/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1131 - val_loss: 0.1228\n",
            "Epoch 21/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1151 - val_loss: 0.1236\n",
            "Epoch 22/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1095 - val_loss: 0.1222\n",
            "Epoch 23/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1116 - val_loss: 0.1213\n",
            "Epoch 24/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1108 - val_loss: 0.1210\n",
            "Epoch 25/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1121 - val_loss: 0.1206\n",
            "Epoch 26/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1101 - val_loss: 0.1211\n",
            "Epoch 27/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1136 - val_loss: 0.1231\n",
            "Epoch 28/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1088 - val_loss: 0.1201\n",
            "Epoch 29/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1101 - val_loss: 0.1211\n",
            "Epoch 30/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - loss: 0.1131 - val_loss: 0.1222\n",
            "Epoch 31/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1060 - val_loss: 0.1209\n",
            "Epoch 32/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1107 - val_loss: 0.1209\n",
            "Epoch 33/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1095 - val_loss: 0.1203\n",
            "Epoch 34/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1060 - val_loss: 0.1211\n",
            "Epoch 35/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1125 - val_loss: 0.1208\n",
            "Epoch 36/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1074 - val_loss: 0.1211\n",
            "Epoch 37/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1118 - val_loss: 0.1210\n",
            "Epoch 38/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1098 - val_loss: 0.1234\n",
            "Epoch 39/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1110 - val_loss: 0.1211\n",
            "Epoch 40/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1104 - val_loss: 0.1243\n",
            "Epoch 41/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1054 - val_loss: 0.1211\n",
            "Epoch 42/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.1076 - val_loss: 0.1219\n",
            "Epoch 43/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1041 - val_loss: 0.1200\n",
            "Epoch 44/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1099 - val_loss: 0.1230\n",
            "Epoch 45/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1115 - val_loss: 0.1206\n",
            "Epoch 46/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1058 - val_loss: 0.1213\n",
            "Epoch 47/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1089 - val_loss: 0.1218\n",
            "Epoch 48/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1128 - val_loss: 0.1213\n",
            "Epoch 49/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1117 - val_loss: 0.1224\n",
            "Epoch 50/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.1076 - val_loss: 0.1208\n",
            "Epoch 51/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1033 - val_loss: 0.1210\n",
            "Epoch 52/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1057 - val_loss: 0.1246\n",
            "Epoch 53/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1081 - val_loss: 0.1232\n",
            "Epoch 54/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1106 - val_loss: 0.1215\n",
            "Epoch 55/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1074 - val_loss: 0.1216\n",
            "Epoch 56/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.1037 - val_loss: 0.1215\n",
            "Epoch 57/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1057 - val_loss: 0.1231\n",
            "Epoch 58/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1123 - val_loss: 0.1240\n",
            "Epoch 59/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1073 - val_loss: 0.1227\n",
            "Epoch 60/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1080 - val_loss: 0.1216\n",
            "Epoch 61/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1074 - val_loss: 0.1218\n",
            "Epoch 62/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1044 - val_loss: 0.1226\n",
            "Epoch 63/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1064 - val_loss: 0.1228\n",
            "Epoch 64/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1088 - val_loss: 0.1223\n",
            "Epoch 65/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.1064 - val_loss: 0.1234\n",
            "Epoch 66/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1066 - val_loss: 0.1244\n",
            "Epoch 67/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1042 - val_loss: 0.1241\n",
            "Epoch 68/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1060 - val_loss: 0.1231\n",
            "Epoch 69/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1063 - val_loss: 0.1230\n",
            "Epoch 70/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.1099 - val_loss: 0.1236\n",
            "Epoch 71/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1026 - val_loss: 0.1251\n",
            "Epoch 72/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1060 - val_loss: 0.1223\n",
            "Epoch 73/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1040 - val_loss: 0.1228\n",
            "Epoch 74/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.1035 - val_loss: 0.1242\n",
            "Epoch 75/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1081 - val_loss: 0.1242\n",
            "Epoch 76/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1043 - val_loss: 0.1238\n",
            "Epoch 77/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1047 - val_loss: 0.1238\n",
            "Epoch 78/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1061 - val_loss: 0.1254\n",
            "Epoch 79/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.1034 - val_loss: 0.1227\n",
            "Epoch 80/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1054 - val_loss: 0.1221\n",
            "Epoch 81/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1065 - val_loss: 0.1220\n",
            "Epoch 82/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1093 - val_loss: 0.1249\n",
            "Epoch 83/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1058 - val_loss: 0.1230\n",
            "Epoch 84/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0979 - val_loss: 0.1224\n",
            "Epoch 85/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1026 - val_loss: 0.1237\n",
            "Epoch 86/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1076 - val_loss: 0.1246\n",
            "Epoch 87/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1054 - val_loss: 0.1262\n",
            "Epoch 88/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1081 - val_loss: 0.1249\n",
            "Epoch 89/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1070 - val_loss: 0.1241\n",
            "Epoch 90/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.1030 - val_loss: 0.1243\n",
            "Epoch 91/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1018 - val_loss: 0.1237\n",
            "Epoch 92/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1050 - val_loss: 0.1244\n",
            "Epoch 93/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.1036 - val_loss: 0.1249\n",
            "Epoch 94/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1012 - val_loss: 0.1238\n",
            "Epoch 95/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1009 - val_loss: 0.1239\n",
            "Epoch 96/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1030 - val_loss: 0.1248\n",
            "Epoch 97/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1011 - val_loss: 0.1240\n",
            "Epoch 98/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1056 - val_loss: 0.1240\n",
            "Epoch 99/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1069 - val_loss: 0.1250\n",
            "Epoch 100/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1047 - val_loss: 0.1242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NutritionRecommender:\n",
        "    def __init__(self, nutrition_data):\n",
        "        self.nutrition_data = nutrition_data\n",
        "\n",
        "    def recommend_nutrition(self, age, stunting_status, weight):\n",
        "        filtered_data = self.nutrition_data[\n",
        "            (self.nutrition_data['usia minimal(bulan)'] <= age) &\n",
        "            (self.nutrition_data['usia maksimal(bulan)'] >= age)\n",
        "        ]\n",
        "\n",
        "        if stunting_status == 'Stunting':\n",
        "            recommended = filtered_data[\n",
        "                (filtered_data['protein (g)'] > filtered_data['protein (g)'].median()) &\n",
        "                (filtered_data['kalori'] > filtered_data['kalori'].median())\n",
        "            ]\n",
        "        else:\n",
        "            recommended = filtered_data\n",
        "\n",
        "        recommended['adjusted_portion'] = recommended['kalori'] * (weight / 10)\n",
        "\n",
        "        return recommended.sort_values('adjusted_portion', ascending=False).head(5)\n",
        "\n",
        "recommender = NutritionRecommender(nutrition_data)\n",
        "recommendations = recommender.recommend_nutrition(age=24, stunting_status='Stunting', weight=10)\n"
      ],
      "metadata": {
        "id": "sjgzTXUmJw2u",
        "outputId": "ab6fadc9-3e0c-412f-a803-3d0137eca5e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-c6628a803681>:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  recommended['adjusted_portion'] = recommended['kalori'] * (weight / 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "23pnwdMJPLJH"
      }
    }
  ]
}